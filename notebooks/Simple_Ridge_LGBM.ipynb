{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from price_prediction import (check_dataframe_features, convert_dataframe_categorical,\n",
    "                    handle_missing_inplace, one_hot_encoding, cutting,\n",
    "                    lower_case_df, clean_sentence, build_crossvalidation_data)\n",
    "\n",
    "DEFAULT_CONDITION_IDS = [1, 2, 3, 4, 5]\n",
    "DEFAULT_SHIPPING_IDS = [0, 1]\n",
    "\n",
    "\n",
    "class NaiveFeaturiser(object):\n",
    "    \"\"\"\n",
    "    The Featuriser class which preprocess inputs, which can\n",
    "    then be appropriately fed into the Model class.\n",
    "\n",
    "    This class consists of pre-processes which are common for\n",
    "    both train and test data.\n",
    "\n",
    "    Here is the list of preprocesses done in this class\n",
    "    built from dataframe-\n",
    "        [1] Checks if dataframe is in appropriate format with all\n",
    "            required fields.\n",
    "        [2] Removes all missing values in the dataframe to 'missing'\n",
    "            value.\n",
    "        [3] Lower case the text fields ['name', 'brand_name',\n",
    "            'item_description'] and normalizes the text.\n",
    "        [4] We build a list of popular brands that have occured a minimum\n",
    "            of 5 times and convert the rest of brand names to 'missing'.\n",
    "        [5] Converts ['item_condition_id', 'shipping'] fields to one hot\n",
    "            encodings.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 brand_names,\n",
    "                 item_condition_set=DEFAULT_CONDITION_IDS,\n",
    "                 shipping_set=DEFAULT_SHIPPING_IDS):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        brand_names: List[str]\n",
    "            List of all popular brand names.\n",
    "        item_condition_set: List[int]\n",
    "            List of all possible item_condition_id values\n",
    "            in request. Default to [1, 2, 3, 4, 5].\n",
    "        shipping_set: List[int]\n",
    "            List of all possible shipping values\n",
    "            in request. Default to [0, 1].\n",
    "        \"\"\"\n",
    "        self.popular_brand_names = brand_names\n",
    "        self.item_condition_set = item_condition_set\n",
    "        self.shipping_set = shipping_set\n",
    "\n",
    "    def __call__(self, data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Calls the featuriser methods, which processes a single\n",
    "        dictionary object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: dict\n",
    "            A dictionary object with induvidual features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        data: dict\n",
    "            A dictionary object with processed features.\n",
    "        \"\"\"\n",
    "        data = self._clean_request(data)\n",
    "        if data['brand_name'] not in self.popular_brand_names:\n",
    "            data['brand_name'] = 'missing'\n",
    "\n",
    "        data['item_condition_id'] = \\\n",
    "            np.array(one_hot_encoding(\n",
    "                data['item_condition_id'],\n",
    "                self.item_condition_set\n",
    "            ), dtype=int)\n",
    "\n",
    "        data['shipping'] = \\\n",
    "            np.array(one_hot_encoding(\n",
    "                data['shipping'],\n",
    "                self.shipping_set\n",
    "            ), dtype=int)\n",
    "\n",
    "        return data\n",
    "\n",
    "    @classmethod\n",
    "    def build_from_dataframe(cls, df_train, df_test=None):\n",
    "        \"\"\"\n",
    "        Builds the featuriser using the dataframe.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df_train: pd.Dataframe\n",
    "            The input dataframe used for building the featuriser.\n",
    "        df_test: pd.Dataframe\n",
    "            The input dataframe used for processing.\n",
    "            Default to None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cls: Naive_Featuriser\n",
    "            Class object for featuriser\n",
    "        df_train: pd.Dataframe\n",
    "            Processed output of df_train\n",
    "        df_test: pd.Dataframe\n",
    "            Processed output of df_test\n",
    "        \"\"\"\n",
    "        required_features = [\n",
    "            \"name\", \"item_condition_id\", \"category_name\", \"brand_name\",\n",
    "            \"shipping\", \"seller_id\", \"item_description\"\n",
    "        ]\n",
    "        check_dataframe_features(df_train, required_features, \"df_train\")\n",
    "        df_train = handle_missing_inplace(df_train)\n",
    "        df_train = lower_case_df(df_train)\n",
    "        df_train[\"name\"] = df_train[\"name\"].apply(clean_sentence)\n",
    "        df_train[\"item_description\"] = \\\n",
    "            df_train[\"item_description\"].apply(clean_sentence)\n",
    "\n",
    "        popular_brand = df_train['brand_name'] \\\n",
    "            .value_counts() \\\n",
    "            .loc[lambda x: x.index != 'missing'] \\\n",
    "            .loc[lambda x: x >= 5].to_dict()\n",
    "        df_train = cutting(df_train, popular_brand)\n",
    "        df_train = convert_dataframe_categorical(df_train, 'item_condition_id',\n",
    "                                                 DEFAULT_CONDITION_IDS)\n",
    "        df_train = convert_dataframe_categorical(df_train, 'shipping',\n",
    "                                                 DEFAULT_SHIPPING_IDS)\n",
    "\n",
    "        if df_test is not None:\n",
    "            check_dataframe_features(df_test, required_features, \"df_test\")\n",
    "            df_test = handle_missing_inplace(df_test)\n",
    "            df_test = lower_case_df(df_test)\n",
    "            df_test[\"name\"] = df_test[\"name\"].apply(clean_sentence)\n",
    "            df_test[\"item_description\"] = \\\n",
    "                df_test[\"item_description\"].apply(clean_sentence)\n",
    "\n",
    "            df_test = cutting(df_test, popular_brand)\n",
    "            df_test = convert_dataframe_categorical(df_test,\n",
    "                                                    'item_condition_id',\n",
    "                                                    DEFAULT_CONDITION_IDS)\n",
    "            df_test = convert_dataframe_categorical(df_test, 'shipping',\n",
    "                                                    DEFAULT_SHIPPING_IDS)\n",
    "\n",
    "        return cls(popular_brand), df_train, df_test\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        Saves the Featuriser in the required path in pickle format.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str\n",
    "            location to save the model.\n",
    "\n",
    "        \"\"\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    \"popular_brands\": self.popular_brand_names,\n",
    "                    \"item_conditions\": self.item_condition_set,\n",
    "                    \"shipping_ids\": self.shipping_set\n",
    "                }, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        \"\"\"\n",
    "        Loads the Featuriser from the required path in pickle format.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str\n",
    "            location to return the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cls: Naive_Featuriser\n",
    "            The class object with loaded weights\n",
    "        \"\"\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            return cls(data[\"popular_brands\"], data[\"item_conditions\"],\n",
    "                       data[\"shipping_ids\"])\n",
    "\n",
    "    def _clean_request(self, data):\n",
    "        \"\"\"\n",
    "        It performs a basic cleaning for all text fields\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: dict\n",
    "            request body\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        data: dict\n",
    "            processed request body\n",
    "        \"\"\"\n",
    "        if data['brand_name'] == \"\":\n",
    "            data['brand_name'] = 'missing'\n",
    "\n",
    "        if data['item_description'] == \"\":\n",
    "            data['brand_name'] = 'missing'\n",
    "\n",
    "        data['name'] = clean_sentence(data['name'].lower())\n",
    "        data['brand_name'] = data['brand_name'].lower()\n",
    "        data['item_description'] = clean_sentence(\n",
    "            data['item_description'].lower())\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "class PricePredictionModel(object):\n",
    "    \"\"\"\n",
    "    The Model class for building the Price Prediction task,\n",
    "    where we build the model from the training dataframe provided\n",
    "    to us. This model performs the following model operations\n",
    "\n",
    "        [1] Building a bag of words model for the [\"name\", \"category_name\"]\n",
    "            features using the CountVectorizer.\n",
    "        [2] One hot encoding for all the major [\"brand_name\"]. We have already\n",
    "            preprocessed it either consist of popular brands or \"missing\".\n",
    "        [3] Tfidf transformation for the [\"item_description\"] feature.\n",
    "        [4] We build two models using the above features\n",
    "            * Ridge Model\n",
    "            * LGBM Model\n",
    "            And the scores from both the models are aggregated.\n",
    "\n",
    "    This class has been built similar to the Scikit Learn API.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 name_f,\n",
    "                 category_f,\n",
    "                 brand_name_f,\n",
    "                 item_descp_f,\n",
    "                 ridge_model,\n",
    "                 lgbm_model,\n",
    "                 fit_performed=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        name_f: Union[dict, CountVectorizer]\n",
    "            arguments for processing the [\"name\"] features.\n",
    "        category_f: Union[dict, CountVectorizer]\n",
    "            arguments for processing the [\"category_name\"] features.\n",
    "        brand_name_f: Union[dict, LabelBinarizer]\n",
    "            arguments for processing the [\"brand_name\"] features.\n",
    "        item_descp_f: Union[dict, TfidfVectorizer]\n",
    "            arguments for processing the [\"item_description\"] features.\n",
    "        ridge_model: Union[dict, Ridge]\n",
    "            the arguments for the Ridge model.\n",
    "        lgbm_model: Union[dict, LGBMRegressor]\n",
    "            the arguments for the LGBM model.\n",
    "        \"\"\"\n",
    "        if isinstance(name_f, dict):\n",
    "            self.feat_name = \\\n",
    "              CountVectorizer(**name_f)\n",
    "        else:\n",
    "            self.feat_name = name_f\n",
    "\n",
    "        if isinstance(category_f, dict):\n",
    "            self.feat_category = \\\n",
    "              CountVectorizer(**category_f)\n",
    "        else:\n",
    "            self.feat_category = category_f\n",
    "\n",
    "        if isinstance(brand_name_f, dict):\n",
    "            self.feat_brand = \\\n",
    "              LabelBinarizer(**brand_name_f)\n",
    "        else:\n",
    "            self.feat_brand = brand_name_f\n",
    "\n",
    "        if isinstance(item_descp_f, dict):\n",
    "            self.feat_item_descp = \\\n",
    "              TfidfVectorizer(**item_descp_f)\n",
    "        else:\n",
    "            self.feat_item_descp = item_descp_f\n",
    "\n",
    "        if isinstance(ridge_model, dict):\n",
    "            self.ridge_model = \\\n",
    "              Ridge(**ridge_model)\n",
    "        else:\n",
    "            self.ridge_model = ridge_model\n",
    "\n",
    "        if isinstance(lgbm_model, dict):\n",
    "            self.lgbm_model = \\\n",
    "              LGBMRegressor(**lgbm_model)\n",
    "        else:\n",
    "            self.lgbm_model = lgbm_model\n",
    "\n",
    "        self.fit_performed = fit_performed\n",
    "\n",
    "    def predict(self, data: dict):\n",
    "        \"\"\"\n",
    "        Predicts the output to a single entry of request\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: dict\n",
    "            The input data to be predicted on.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred: int\n",
    "            The predicted price.\n",
    "        \"\"\"\n",
    "        if self.fit_performed is False:\n",
    "            raise AssertionError(\"Build the model with `fit` method and \"\n",
    "                                 \"then use `predict` method.\")\n",
    "\n",
    "        x_name = self.feat_name.transform([data[\"name\"]])\n",
    "        x_cat = self.feat_category.transform([data[\"category_name\"]])\n",
    "        x_brand = self.feat_brand.transform([data[\"brand_name\"]])\n",
    "        x_item = self.feat_item_descp.transform([data[\"item_description\"]])\n",
    "        x_ict = data[\"item_condition_id\"]\n",
    "        x_ship = data[\"shipping\"]\n",
    "        x = hstack((x_ict, x_ship, x_item, x_brand, x_cat, x_name)).tocsr()\n",
    "        pred = 0.47 * self.lgbm_model.predict(x)\n",
    "        pred += 0.53 * self.lgbm_model.predict(x)\n",
    "        pred = np.expm1(pred)\n",
    "        return pred.item()\n",
    "\n",
    "    def fit(self, df_train: pd.DataFrame, df_valid: pd.DataFrame = None):\n",
    "        \"\"\"\n",
    "        Used to build the models.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df_train: pd.DataFrame\n",
    "            The training data to build the model.\n",
    "        df_valid: pd.DataFrame\n",
    "            The validation data to infer the model performance. Default on None\n",
    "        \"\"\"\n",
    "        Y_train = np.log1p(df_train[\"price\"])\n",
    "        X_name_train = self.feat_name.fit_transform(df_train['name'])\n",
    "        X_category_train = \\\n",
    "            self.feat_category.fit_transform(df_train['category_name'])\n",
    "        X_brand_train = \\\n",
    "            self.feat_brand.fit_transform(df_train['brand_name'])\n",
    "        X_item_train = \\\n",
    "            self.feat_item_descp.fit_transform(df_train['item_description'])\n",
    "        X_item_condition_train = csr_matrix(\n",
    "            df_train.loc[:,\n",
    "                         'item_condition_id_1':'item_condition_id_5'].values)\n",
    "        X_shipping_train = csr_matrix(\n",
    "            df_train.loc[:, 'shipping_0':'shipping_1'].values)\n",
    "        X_train = hstack(\n",
    "            (X_item_condition_train, X_shipping_train, X_item_train,\n",
    "             X_brand_train, X_category_train, X_name_train)).tocsr()\n",
    "\n",
    "        self.lgbm_model = self.lgbm_model.fit(X_train, Y_train)\n",
    "        pred_train = 0.53 * self.lgbm_model.predict(X_train)\n",
    "\n",
    "        self.ridge_model.fit(X_train, Y_train)\n",
    "        pred_train += 0.47 * self.ridge_model.predict(X_train)\n",
    "        train_error = mean_squared_error(Y_train, pred_train, squared=False)\n",
    "        print(f\"Train Error - {train_error:5.3f}\")\n",
    "        if df_valid is not None:\n",
    "            Y_val = np.log1p(df_valid[\"price\"])\n",
    "            X_name_val = self.feat_name.transform(df_valid['name'])\n",
    "            X_category_val = \\\n",
    "                self.feat_category.transform(df_valid['category_name'])\n",
    "            X_brand_val = \\\n",
    "                self.feat_brand.transform(df_valid['brand_name'])\n",
    "            X_item_val = \\\n",
    "                self.feat_item_descp.transform(df_valid['item_description'])\n",
    "            X_item_condition_val = csr_matrix(\n",
    "                df_valid.loc[:, 'item_condition_id_1':'item_condition_id_5'].\n",
    "                values)\n",
    "            X_shipping_val = csr_matrix(\n",
    "                df_valid.loc[:, 'shipping_0':'shipping_1'].values)\n",
    "            X_val = hstack((X_item_condition_val, X_shipping_val, X_item_val,\n",
    "                            X_brand_val, X_category_val, X_name_val)).tocsr()\n",
    "            pred_val = 0.53 * self.lgbm_model.predict(X_val)\n",
    "            pred_val += 0.47 * self.ridge_model.predict(X_val)\n",
    "\n",
    "            val_error = mean_squared_error(Y_val, pred_val, squared=False)\n",
    "            print(f\"Validation Error - {val_error:5.3f} \\n\")\n",
    "\n",
    "        self.fit_performed = True\n",
    "\n",
    "    def predict_df(self, dataset: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Predicts the output for dataframe\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pd.DataFrame\n",
    "            The input data to be predicted on.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred: np.ndarray\n",
    "            The predicted price.\n",
    "        \"\"\"\n",
    "        if self.fit_performed is False:\n",
    "            raise AssertionError(\"Build the model with `fit` method and \"\n",
    "                                 \"then use `predict_df` method.\")\n",
    "        X_name = self.feat_name.transform(dataset['name'])\n",
    "        X_category = self.feat_category.transform(dataset['category_name'])\n",
    "        X_brand = self.feat_brand.transform(dataset['brand_name'])\n",
    "        X_item = self.feat_item_descp.transform(dataset['item_description'])\n",
    "        X_item_condition = csr_matrix(\n",
    "            dataset.loc[:, 'item_condition_id_1':'item_condition_id_5'].values)\n",
    "        X_shipping = csr_matrix(dataset.loc[:,\n",
    "                                            'shipping_0':'shipping_1'].values)\n",
    "        X = hstack((X_item_condition, X_shipping, X_item, X_brand, X_category,\n",
    "                    X_name)).tocsr()\n",
    "        pred = 0.53 * self.lgbm_model.predict(X)\n",
    "        pred += 0.47 * self.ridge_model.predict(X)\n",
    "        pred = np.expm1(pred)\n",
    "        return pred\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        Saves the model weights in the required path in pickle format.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str\n",
    "            location to save the model.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.fit_performed is False:\n",
    "            raise AssertionError(\"Build the model with `fit` method and \"\n",
    "                                 \"then use `save` method.\")\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    \"name_featuriser\": self.feat_name,\n",
    "                    \"category_featuriser\": self.feat_category,\n",
    "                    \"brand_featuriser\": self.feat_brand,\n",
    "                    \"item_desc_featuriser\": self.feat_item_descp,\n",
    "                    \"ridge_model\": self.ridge_model,\n",
    "                    \"lgbm_model\": self.lgbm_model\n",
    "                }, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        \"\"\"\n",
    "        Loads the model weights from the required path in pickle format.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str\n",
    "            location to return the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cls: PricePredictionModel\n",
    "            The class object with loaded weights\n",
    "        \"\"\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            return cls(data[\"name_featuriser\"],\n",
    "                       data[\"category_featuriser\"],\n",
    "                       data[\"brand_featuriser\"],\n",
    "                       data[\"item_desc_featuriser\"],\n",
    "                       data[\"ridge_model\"],\n",
    "                       data[\"lgbm_model\"],\n",
    "                       fit_performed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import os\n",
    "\n",
    "data_path = join(*[os.pardir, \"data\"])\n",
    "df_train = pd.read_csv(join(data_path, \"mercari_train.csv\"))\n",
    "df_test = pd.read_csv(join(data_path, \"mercari_test.csv\"))\n",
    "featuriser, df_train, df_test = NaiveFeaturiser \\\n",
    "    .build_from_dataframe(df_train, df_test)\n",
    "# Saving the Featuriser weights\n",
    "# featuriser.save(join(save_path, \"featuriser.pkl\"))\n",
    "\n",
    "train_datasets, val_datasets = \\\n",
    "    build_crossvalidation_data(df_train, split=3)\n",
    "name_args = {\n",
    "    'max_features': 1000,\n",
    "    'min_df': 10,\n",
    "    'stop_words': 'english',\n",
    "}\n",
    "category_args = {}\n",
    "brand_args = {'sparse_output': True}\n",
    "item_args = {\n",
    "    'max_features': 500,\n",
    "    'ngram_range': (1, 3),\n",
    "    'stop_words': 'english'\n",
    "}\n",
    "ridge_model_args = {\n",
    "    'solver': \"auto\",\n",
    "    'fit_intercept': True,\n",
    "    'random_state': 205\n",
    "}\n",
    "\n",
    "lgbm_args = {\n",
    "    'learning_rate': 0.75,\n",
    "    'max_depth': 2,\n",
    "    'num_leaves': 50,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'RMSE'\n",
    "}\n",
    "\n",
    "for i, dataset in enumerate(zip(train_datasets, val_datasets)):\n",
    "    train, val = dataset\n",
    "    print(f\"Fold {i} \\n\")\n",
    "    model = PricePredictionModel(\n",
    "        name_args, category_args,\n",
    "        brand_args, item_args,\n",
    "        ridge_model_args,\n",
    "        lgbm_args\n",
    "    )\n",
    "    model.predict_df(train)\n",
    "    model.fit(train, val)\n",
    "    # model.save(join(save_path, f\"Mega_model_{i}.pkl\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
